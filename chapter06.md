# Chapter 6: Background on regression modeling

[(Return to README)](./README.md)

"At a purely mathematical level," the book wants you to use regression for
prediction and/or comparison.  Comparison has a special case where you're
comparing treatment and control outcomes to estimate a causal effect.

## Subsection rundown

### 6.1, Regression models

Jargon check: in the "basic regression model" expression

$$y = a + bx + \text{error}$$

"The quantities $a$ and $b$ are *coefficients* or, more generally, *parameters*
of the model."

The book is going to focus on four extensions of that basic model:
additional predictors, nonlinear models (like log-transforming $y$ and $x$),
nonadditive models (e.g., you have a term for the product of two other
predictors), and generalized linear models (wrap the basic model in an
activation function).

This means *not* focusing on the listed extensions of nonparametric models,
multilevel models, and measurement error models.

### 6.2, Fitting a simple regression to fake data

TK

### 6.3, Interpret coefficients as comparisons, not effects

TK 

### 6.4, Historical origins of regression

TK 

### 6.5, The paradox of regression to the mean

TK

## Exercises

TK